{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as manim\n",
    "from skimage.measure import find_contours\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import pylidc as pl\n",
    "from pylidc.utils import consensus\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "import matplotlib.path as mplpath\n",
    "import cv2\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change deprecated functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_matrix(self, include_k=True):\n",
    "    ij = np.array([[int(cc) for cc in c.split(',')][::-1] for c in self.coords.split('\\n')])\n",
    "    if not include_k:\n",
    "        return ij\n",
    "    else:\n",
    "        k  = np.ones(ij.shape[0])*self.image_k_position\n",
    "        zs = self.annotation.contour_slice_zvals\n",
    "        return np.c_[ij, k].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boolean_mask(self, pad=None, bbox=None, include_contour_points=False):\n",
    "    bb = self.bbox_matrix(pad=pad) if bbox is None else bbox\n",
    "\n",
    "    czs = self.contour_slice_zvals\n",
    "    cks = self.contour_slice_indices\n",
    "\n",
    "    zs = self.scan.slice_zvals\n",
    "    zs = zs[cks[0]:cks[-1]+1]\n",
    "\n",
    "    z_to_index = lambda z: dict(zip(czs,cks))[z] - bb[2,0]\n",
    "\n",
    "    ni,nj,nk = np.diff(bb, axis=1).astype(int)[:,0] + 1\n",
    "\n",
    "    ni, nj, _ = np.amax(bb, axis=1)\n",
    "\n",
    "    print(ni, nj)\n",
    "\n",
    "    mask = np.zeros((ni,nj,nk), dtype=np.bool)\n",
    "\n",
    "    ii,jj = np.indices(mask.shape[:2])\n",
    "    test_points = bb[:2,0] + np.c_[ii.flatten(), jj.flatten()]\n",
    "\n",
    "    for contour in self.contours:\n",
    "        if contour.inclusion:\n",
    "            zi = z_to_index(contour.image_z_position)\n",
    "            C  = contour.to_matrix(include_k=False)\n",
    "\n",
    "            if (C[0] != C[-1]).any():\n",
    "                C = np.append(C, C[0].reshape(1,2), axis=0)\n",
    "\n",
    "            path = mplpath.Path(C, closed=True)\n",
    "            contains_pts = path.contains_points(test_points)\n",
    "            contains_pts = contains_pts.reshape(mask.shape[:2])\n",
    "\n",
    "            mask[:,:,zi] = np.logical_or(mask[:,:,zi], contains_pts)\n",
    "\n",
    "            if not include_contour_points:\n",
    "                i, j = (C - bb[:2,0]).T\n",
    "                k = np.ones(C.shape[0], dtype=np.int32)*zi\n",
    "                mask[i,j,k] = False\n",
    "\n",
    "    for contour in self.contours:\n",
    "        if not contour.inclusion:\n",
    "            zi = z_to_index(contour.image_z_position)\n",
    "            C = contour.to_matrix(include_k=False)\n",
    "\n",
    "            if (C[0] != C[-1]).any():\n",
    "                C = np.append(C, C[0].reshape(1,2), axis=0)\n",
    "\n",
    "            path = mplpath.Path(C, closed=True)\n",
    "            not_contains_pts = ~path.contains_points(test_points)\n",
    "            not_contains_pts = not_contains_pts.reshape(mask.shape[:2])\n",
    "            mask[:,:,zi] = np.logical_and(mask[:,:,zi], not_contains_pts)\n",
    "\n",
    "            i, j = (C - bb[:2,0]).T\n",
    "            k = np.ones(C.shape[0], dtype=np.int32)*zi\n",
    "            mask[i,j,k] = False\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consensus(anns, clevel=0.5, pad=None, ret_masks=True):\n",
    "    bmats = np.array([a.bbox_matrix(pad=pad) for a in anns])\n",
    "    imin,jmin,kmin = bmats[:,:,0].min(axis=0)\n",
    "    imax,jmax,kmax = bmats[:,:,1].max(axis=0)\n",
    "\n",
    "    # consensus_bbox\n",
    "    cbbox = np.array([[imin,imax], [jmin,jmax], [kmin,kmax]])\n",
    "\n",
    "    masks = [a.boolean_mask(bbox=cbbox) for a in anns]\n",
    "    cbbox = tuple(slice(cb[0], cb[1]+1, None) for cb in cbbox)\n",
    "    cmask = np.mean(masks, axis=0) >= clevel\n",
    "\n",
    "    if ret_masks:\n",
    "        return cmask, cbbox, masks\n",
    "    else:\n",
    "        return cmask, cbbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_in_scan(self, verbose=True):\n",
    "        images = self.scan.load_all_dicom_images(verbose)\n",
    "\n",
    "        image_array = []\n",
    "        \n",
    "        # Preload contours and sort them by z pos.\n",
    "        contours = sorted(self.contours, key=lambda c: c.image_z_position)\n",
    "        fnames = self.scan.sorted_dicom_file_names.split(',')\n",
    "        index_of_contour = [fnames.index(c.dicom_file_name) for c in contours]\n",
    "        \n",
    "        for current_slice in index_of_contour:\n",
    "\n",
    "            img = images[current_slice].pixel_array\n",
    "            image_array.append(img)\n",
    "\n",
    "        contour_lines = []\n",
    "\n",
    "        for c in contours:\n",
    "            arr = c.to_matrix()\n",
    "            contour_lines.append([arr[:,1], arr[:,0]])\n",
    "\n",
    "        return image_array, contour_lines, index_of_contour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.Contour.to_matrix = to_matrix\n",
    "pl.Annotation.boolean_mask = boolean_mask\n",
    "pl.Annotation.visualize_in_scan = visualize_in_scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder structure created (or already exists).\n"
     ]
    }
   ],
   "source": [
    "def create_folder_structure(parent_path):\n",
    "    # Define the directory structure\n",
    "    directories = [\n",
    "        os.path.join(parent_path, 'images', 'train'),\n",
    "        os.path.join(parent_path, 'images', 'val'),\n",
    "        os.path.join(parent_path, 'labels', 'train'),\n",
    "        os.path.join(parent_path, 'labels', 'val')\n",
    "    ]\n",
    "    \n",
    "    for directory in directories:\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    print(\"Folder structure created (or already exists).\")\n",
    "\n",
    "parent_path = 'CT'  # Replace with your desired parent directory path\n",
    "create_folder_structure(parent_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dicom files ... This may take a moment.\n",
      "Loading dicom files ... This may take a moment.\n",
      "Loading dicom files ... This may take a moment.\n",
      "Loading dicom files ... This may take a moment.\n"
     ]
    }
   ],
   "source": [
    "def save_annotation(contour, w, h, annotation_file):\n",
    "    min_x, max_x = min(contour[0]), max(contour[0])\n",
    "    min_y, max_y = min(contour[1]), max(contour[1])\n",
    "    cx, cy = ((min_x + max_x) / 2) / w, ((min_y + max_y) / 2) / h\n",
    "    width, height = (max_x - min_x) / w, (max_y - min_y) / h\n",
    "    annotation_file.write(f\"0 {cx} {cy} {width} {height}\\n\")\n",
    "\n",
    "def process_and_save_image(image, contour, patient_id, i, j, dataset_path, annotation_path, transform_name, flip_axis=None):\n",
    "    if flip_axis is not None:\n",
    "        image = Image.fromarray(np.flip(np.array(image), flip_axis))\n",
    "        contour = [contour[0] if flip_axis == 0 else image.width - contour[0],\n",
    "                   contour[1] if flip_axis == 1 else image.height - contour[1]]\n",
    "    \n",
    "    annotation_file_path = os.path.join(annotation_path, f\"{patient_id}_{transform_name}_annotation_{j}_image_{i}.txt\")\n",
    "    with open(annotation_file_path, \"a\") as f:\n",
    "        save_annotation(contour, image.width, image.height, f)\n",
    "    \n",
    "    image.save(os.path.join(dataset_path, f\"{patient_id}_{transform_name}_annotation_{j}_image_{i}.jpg\"), \"JPEG\")\n",
    "\n",
    "global_path = ''\n",
    "\n",
    "directory_list = [0] * 70 + [1] * 30\n",
    "\n",
    "dataset_directory_list = ['datasets/train', 'datasets/val']\n",
    "annotation_directory_list = ['annotations/train', 'annotations/val']\n",
    "\n",
    "scanLIDC_IDRI = pl.query(pl.Scan)\n",
    "for scan in scanLIDC_IDRI:\n",
    "    patient_id = scan.patient_id\n",
    "    for annotation in scan.cluster_annotations():\n",
    "        for j, ann in enumerate(annotation):\n",
    "            PIL_images = []\n",
    "            images, contours, index = ann.visualize_in_scan()\n",
    "            for image in images: \n",
    "                image_ = cv2.bilateralFilter(image.astype(np.float32), 5, 12.0, 16.0)\n",
    "                PIL_images.append(Image.fromarray(image_).convert('RGB'))\n",
    "            for i, contour in enumerate(contours):\n",
    "                directory_choice = random.choice(directory_list)\n",
    "                dataset_path = os.path.join(global_path, dataset_directory_list[directory_choice])\n",
    "                annotation_path = os.path.join(global_path, annotation_directory_list[directory_choice])\n",
    "                \n",
    "                process_and_save_image(PIL_images[i], contour, patient_id, i, j, dataset_path, annotation_path, \"normal\")\n",
    "                process_and_save_image(PIL_images[i], contour, patient_id, i, j, dataset_path, annotation_path, \"horizontal_flipped\", flip_axis=1)\n",
    "                process_and_save_image(PIL_images[i], contour, patient_id, i, j, dataset_path, annotation_path, \"vertical_flipped\", flip_axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(\"yolov8m.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.train(data=\"test.yaml\", time=0.2, patience=5, single_cls=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_= YOLO('runs/detect/train/weights/best.pt')\n",
    "#results_ = model_.val('annotation_0_image_0.jpg')\n",
    "\n",
    "maP_50 = results.results_dict['metrics/mAP50-95(B)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maP_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
